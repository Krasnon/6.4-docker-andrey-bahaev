# Деплой Prometheus с помощью Docker

```sh
docker run \
  -p 9090:9090 \
  -v ./prometheus/config:/etc/prometheus \
  --name prometheus \
  prom/prometheus
```

# Получаем метрики с хоста c помощью node_exporter

```yaml
- job_name: "docker_server"
  # metrics_path defaults to '/metrics'
  # scheme defaults to 'http'.
  static_configs:
    - targets: ["172.17.0.1:9100"]
```

# Перезапускаем контейнер:
```sh
docker stop prometheus
docker start prometheus
```

# Структура docker-compose.yml

## Основа сценария
```yaml
version: '3'
services:
  netology-app:
volumes:
  netology-lesson:
networks:
  netology-lesson:
```

## Основа docker-compose.yml для стека мониторинга
```yaml
version: '3'
services:
volumes:
networks:
  monitoring-stack:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: 10.5.0.1
```

# Добавляем Prometheus

<!--
Мы используем образ prom/prometheus с версией v2.47.2
Контейнер будет называться prometheus
Во время обращения на IP-адрес Docker сервера на порт 9090 он будет прокинут внутрь контейнера Prometheus на порт 9090
Локальная директория на Docker сервере ./prometheus прокидывается в контейнер prometheus в папку /etc/prometheus
Создан Volume для сохранения данных директории /prometheus контейнера
Контейнер использует сеть monitoring-stack
Также контейнер запускается с параметром постоянного перезапуска в случае падения
-->

```yaml
version: '3'
services:
  prometheus:
    image: prom/prometheus:v2.47.2
    container_name: prometheus
    command: --web.enable-lifecycle --config.file=/etc/prometheus/prometheus.yml
    ports:
      - 9090:9090
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    networks:
      - monitoring-stack
    restart: always
volumes:
  prometheus-data:
networks:
  monitoring-stack:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: 10.5.0.1
```

# Пробный запуск сценария
```sh
sudo docker-compose up # запуск с выводом в консоль
sudo docker-compose up -d # запуск в бэкграунде
sudo docker-compose -f anything.yml up # запуск в случае если файл называется нетипично
```

# Добавляем Pushgateway

<!--
Мы используем образ prom/pushgateway с тегом (версией) v1.6.2
Контейнер будет называться pushgateway
Во время обращения на IP-адрес Docker сервера на порт 9091 он будет прокинут внутрь контейнера pushgateway на порт 9091
Контейнер использует сеть monitoring-stack
Приложение будет запущено только после запуска prometheus
Также контейнер будет перезапускаться в случае падения, если только он не был остановлен намеренно
-->

```yaml
version: '3'
services:
  pushgateway:
    image: prom/pushgateway:v1.6.2
    container_name: pushgateway
    ports:
      - 9091:9091
    networks:
      - monitoring-stack
    depends_on:
      - prometheus
    restart: unless-stopped
networks:
  monitoring-stack:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: 10.5.0.1
```

# Проверка Pushgateway
## Нацеливаем prometheus на pushgateway:
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'pushgateway'
    honor_labels: true
    static_configs:
      - targets: ['pushgateway:9091']
```

## Пушим метрику в Pushgateway:
```sh
echo "docker 2" | curl --data-binary @- http://localhost:9091/metrics/job/netology
```

# Добавляем Alertmanager

<!--
Мы используем образ prom/alertmanager с конкретным тегом — версией 0.26.0
Контейнер будет называться alertmanager
Во время обращения на IP-адрес Docker сервера на порт 9093 он будет прокинут внутрь контейнера alertmanager на порт 9093
Локальная директория на Docker сервере ./alertmanager прокидывается в контейнер alertmanager в папку /etc/alertmanager
Создан Volume для сохранения данных директории /data контейнера
Контейнер использует сеть monitoring-stack
Приложение будет запущено только после запуска prometheus
Также контейнер запускается с параметром постоянного перезапуска в случае падения
-->

```yaml
version: '3'
services:
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager
    command: --config.file=/etc/alertmanager/alertmanager.yml
    ports:
      - 9093:9093
    volumes:
      - ./alertmanager:/etc/alertmanager
      - alertmanager-data:/data
    networks:
      - monitoring-stack
    depends_on:
      - prometheus
    restart: always
volumes:
  alertmanager-data:
networks:
  monitoring-stack:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: 10.5.0.1
```

# Проверка Alertmanager
## Добавляем правило алертинга в конфигурацию prometheus и нацеливаем его на alertmanager:
```yaml
# prometheus.yml
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093
rule_files:
  - alerts.yml
```

```yaml
# alerts.yml
groups:
  - name: Netology
    rules:
      - alert: Danger
        expr: docker{job="netology"} > 1
        for: 10s
```

# Добавляем сценарий для Grafana

<!--
Мы используем образ grafana/grafana без тега, что автоматом означает тег latest
Контейнер будет называться grafana
С помощью переменной среды, поддерживаемой контейнером, мы задаём путь до кастомной конфигурации, где прописаны логин и пароль администратора
Во время обращения на IP-адрес Docker сервера на порт 80 он будет прокинут внутрь контейнера grafana на порт 3000
Локальная директория на Docker сервере ./grafana/provisioning прокидывается в контейнер grafana в папку /etc/grafana
Создан Volume для сохранения данных директории /var/lib/grafana контейнера
Контейнер использует сеть monitoring-stack
Приложение будет запущено только после запуска prometheus
Также контейнер будет перезапускаться в случае падения, если он не был остановлен намеренно
-->

```yaml
version: '3'
services:
  grafana:
    image: grafana/grafana
    container_name: grafana
    environment:
      - GF_PATHS_CONFIG=/etc/grafana/custom.ini
    ports:
      - 80:3000
    volumes:
      - ./grafana:/etc/grafana
      - grafana-data:/var/lib/grafana
    networks:
      - monitoring-stack
    depends_on:
      - prometheus
    restart: unless-stopped
volumes:
  grafana-data:
networks:
  monitoring-stack:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: 10.5.0.1
```